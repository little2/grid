



import os
import time
import json
import numpy as np
from pathlib import Path
from PIL import Image, ImageDraw, ImageFont
from moviepy.editor import VideoFileClip
from insightface.app import FaceAnalysis
from insightface.utils import face_align
from sklearn.cluster import DBSCAN
import imagehash

def smart_extract_hero_frames(video_path: str) -> list[Image.Image]:
    """
    æ™ºèƒ½åˆ†æè§†é¢‘å¸§ï¼Œé€‰å‡ºä¸»è§’å›¾ä¸ºä¸»å›¾ï¼Œå…¶ä½™å¸§æŒ‰æ—¶é—´åˆ†å¸ƒæŒ‘é€‰ä¸ºå‰¯å›¾ï¼Œç¡®ä¿å¤šæ ·æ€§
    """
    clip = VideoFileClip(video_path, audio=False)
    duration = clip.duration
    if duration <= 0:
        raise RuntimeError("è§†é¢‘æ—¶é•¿ä¸º 0")

    print(f"ğŸ“¹ æ­£åœ¨åˆ†æè§†é¢‘ï¼š{video_path}", flush=True)
    # âœ… åŠ¨æ€æŠ½å¸§æ•°
    if duration < 10:
        total = 10
    elif duration < 30:
        total = 30
    elif duration < 60:
        total = 40
    elif duration < 180:
        total = 60
    elif duration < 600:
        total = 90
    else:
        total = 120


    print(f"â± è§†é¢‘æ€»æ—¶é•¿ï¼š{duration:.2f}sï¼Œå‡†å¤‡æŠ½å– {total} å¸§", flush=True)


    # åˆå§‹åŒ– InsightFace
    app = FaceAnalysis(name="buffalo_l")
    app.prepare(ctx_id=0, det_size=(640, 640))

    times = [(i + 1) * duration / (total + 1) for i in range(total)]
    all_frames = []         # æ¯å¸§: {'index': i, 'time': t, 'image': img}
    frame_data = []         # æœ‰äººè„¸çš„å¸§
    embeddings = []
    face_frame_map = []

    for i, t in enumerate(times):
        try:
            frame = clip.get_frame(t)
            img = Image.fromarray(frame).convert("RGB")
            all_frames.append({'index': i, 'time': t, 'image': img})

            faces = app.get(frame)
            if faces:
                print(f"âœ… æ£€æµ‹åˆ° {len(faces)} å¼ äººè„¸", flush=True)
                frame_record = {
                    "index": i,
                    "image": img,
                    "faces": faces,
                }
                frame_data.append(frame_record)

                for face in faces:

                    emb = face.normed_embedding
                    if emb is not None:
                        embeddings.append(emb)
                        face_frame_map.append(len(frame_data) - 1)
        except Exception as e:
            print(f"âš ï¸ ç¬¬ {t:.2f}s æŠ½å¸§å¤±è´¥ï¼š{e}")

    if not frame_data:
        print("âš ï¸ è§†é¢‘ä¸­æ— æ£€æµ‹åˆ°äººè„¸ï¼Œä¸»å›¾å°†ä½¿ç”¨ç¬¬ 0 å¸§")
        return [all_frames[0]['image']] + [fr['image'] for fr in all_frames[1:9]]

    # ä¸»å›¾é€»è¾‘ï¼ˆèšç±» + æœ€å¤§è„¸é¢ç§¯ï¼‰
    if len(embeddings) >= 2:
        embeddings = np.array(embeddings)
        clustering = DBSCAN(eps=0.4, min_samples=2, metric='cosine').fit(embeddings)
        labels = clustering.labels_

        label_counts = {l: labels.tolist().count(l) for l in set(labels) if l != -1}
        if label_counts:
            main_label = max(label_counts, key=label_counts.get)
            main_face_indices = [i for i, label in enumerate(labels) if label == main_label]
            candidate_frame_indices = list({face_frame_map[i] for i in main_face_indices})

            def face_area(face): return (face.bbox[2] - face.bbox[0]) * (face.bbox[3] - face.bbox[1])
            main_frame = max(
                (frame_data[i] for i in candidate_frame_indices),
                key=lambda fr: sum(face_area(f) for f in fr["faces"])
            )
        else:
            main_frame = frame_data[0]
    else:
        main_frame = frame_data[0]

    main_img = main_frame["image"]
    main_frame_idx = main_frame["index"]
    print(f"ğŸ‘‘ ä¸»å›¾é‡‡ç”¨ç¬¬ {main_frame_idx + 1} å¼ å¸§")

    # âœ… æŒ‘é€‰å‰¯å›¾ï¼šä» all_frames ä¸­æŒ‰ index å‡åŒ€åˆ†å¸ƒæŒ‘ 8 å¼ ï¼Œè·³è¿‡ä¸»å›¾å¸§
    print("ğŸ§  æ­£åœ¨æŒ‘é€‰å·®å¼‚æ€§æœ€å¤§çš„å‰¯å›¾...", flush=True)



    # è®¡ç®— hash
    for f in all_frames:
        f['hash'] = imagehash.average_hash(f['image'])

    # æ’é™¤ä¸»å›¾å¸§
    used_indices = {main_frame_idx}
    candidates = [f for f in all_frames if f['index'] != main_frame_idx]

    # é€‰ç¬¬ä¸€å¼ å‰¯å›¾ï¼šå–æ—¶é—´çº¦ 1/8 çš„ä½ç½®ä½œä¸ºèµ·å§‹ç‚¹
    first_idx = len(candidates) // 8
    first_candidate = candidates[first_idx]
    selected = [first_candidate]
    selected_hashes = [first_candidate['hash']]
    used_indices.add(first_candidate['index'])

    # é€‰å…¶ä½™ 7 å¼ å‰¯å›¾ï¼ˆè´ªå¿ƒæŒ‘ hash å·®å¼‚æœ€å¤§ï¼‰
    for _ in range(7):
        best_score = -1
        best_frame = None
        for f in candidates:
            if f['index'] in used_indices:
                continue
            min_distance = min(f['hash'] - h for h in selected_hashes)
            if min_distance > best_score:
                best_score = min_distance
                best_frame = f
        if best_frame:
            selected.append(best_frame)
            selected_hashes.append(best_frame['hash'])
            used_indices.add(best_frame['index'])

    # æœ€ç»ˆæŒ‰æ—¶é—´æ’åº
    selected_sorted = sorted(selected, key=lambda f: f['time'])
    other_imgs = [f['image'] for f in selected_sorted]

    print("âœ… å‰¯å›¾é€‰æ‹©å®Œæˆï¼šå·²ç¡®ä¿å†…å®¹å·®å¼‚æ€§ + æ—¶é—´é¡ºåº", flush=True)

    return [main_img] + other_imgs



def extract_n_frames(video_path: str, n: int = 9) -> list[Image.Image]:
    
    
    
    """
    ä»è§†é¢‘ç­‰é—´è·æŠ½å– n å¼ å¸§å›¾ï¼ˆè¿”å› PIL.Image åˆ—è¡¨ï¼‰
    """
    clip = VideoFileClip(video_path)
    duration = clip.duration
    if duration <= 0:
        raise RuntimeError("âŒ è§†é¢‘æ—¶é•¿ä¸º 0ï¼Œæ— æ³•å¤„ç†ã€‚")

    times = [(i + 1) * duration / (n + 1) for i in range(n)]
    frames = []
    for t in times:
        try:
            frame = clip.get_frame(t)
            frames.append(Image.fromarray(frame).convert("RGB"))
        except Exception as e:
            print(f"âš ï¸ æŠ½å¸§å¤±è´¥ @ {t:.2f}sï¼š{e}")

    if len(frames) < n:
        raise RuntimeError(f"âŒ ä»…æˆåŠŸæŠ½å– {len(frames)} å¼ å›¾ï¼Œå°‘äºæœŸæœ› {n} å¼ ã€‚")

    return frames


def compose_hero_grid(
    images: list[Image.Image],
    output_path: str,
    font_path: str = "fonts/Roboto_Condensed-Regular.ttf",
    watermark_text: str = None
) -> str:
    """
    æ¥æ”¶ 9 å¼ å›¾ï¼ˆ1 ä¸»å›¾ + 8 å‰¯å›¾ï¼‰ï¼Œç”Ÿæˆä¸»å›¾+è¾…å›¾ä¹å®«æ ¼ï¼ˆ3Ã—4ï¼‰
    """

    if len(images) != 9:
        raise ValueError("å¿…é¡»ä¼ å…¥ 9 å¼ å›¾åƒï¼š1 ä¸»å›¾ + 8 å‰¯å›¾")

    # ç¡®ä¿ç»Ÿä¸€æ ¼å¼
    images = [img.convert("RGB") for img in images]

    # å°ºå¯¸ä»¥å‰¯å›¾ä¸ºåŸºå‡†
    unit_w, unit_h = images[1].size
    hero_w, hero_h = unit_w * 2, unit_h * 2
    grid_w, grid_h = unit_w * 3, unit_h * 4
    grid_img = Image.new("RGBA", (grid_w, grid_h))

    # ä¸»å›¾ï¼ˆå·¦ä¸Š 2Ã—2ï¼‰
    grid_img.paste(images[0].resize((hero_w, hero_h)), (0, 0))

    # å‰¯å›¾å¸ƒå±€
    grid_positions = [
        (2, 0), (2, 1),
        (0, 2), (1, 2), (2, 2),
        (0, 3), (1, 3), (2, 3),
    ]

    for idx, (gx, gy) in enumerate(grid_positions):
        img = images[idx + 1].resize((unit_w, unit_h))
        grid_img.paste(img, (gx * unit_w, gy * unit_h))

    # æ·»åŠ æµ®æ°´å°
    draw = ImageDraw.Draw(grid_img)
    font_size = int(unit_h * 0.3)
    try:
        font = ImageFont.truetype(font_path, size=font_size)
    except Exception:
        print(f"âš ï¸ æ— æ³•åŠ è½½å­—ä½“ï¼š{font_path}ï¼Œä½¿ç”¨é»˜è®¤å­—ä½“")
        font = ImageFont.load_default()

    text = watermark_text or Path(output_path).stem
    try:
        text_width, text_height = font.getsize(text)
    except AttributeError:
        bbox = draw.textbbox((0, 0), text, font=font)
        text_width, text_height = bbox[2] - bbox[0], bbox[3] - bbox[1]

    draw.text(
        (grid_img.width - text_width - 10, grid_img.height - text_height - 10),
        text, font=font, fill=(255, 255, 255, 200)
    )

    # è¾“å‡ºä¿å­˜
    Path(output_path).parent.mkdir(parents=True, exist_ok=True)
    grid_img.convert("RGB").save(output_path, quality=90)
    print(f"âœ… å·²ç”Ÿæˆä¹å®«æ ¼é¢„è§ˆå›¾ï¼š{output_path}")
    return output_path


# === ç¤ºä¾‹è°ƒç”¨ ===
if __name__ == "__main__":
    video_path = "video5.mp4"
    output_path = "preview_demo.jpg"
    font_path = "fonts/Roboto_Condensed-Regular.ttf"

    frames = smart_extract_hero_frames(video_path)
    compose_hero_grid(frames, output_path, font_path=font_path, watermark_text="DEMO")


# utils/hero_grid_video.py
import os
import time
from pathlib import Path
from typing import List, Tuple, Dict, Any, Optional

import numpy as np
from PIL import Image, ImageDraw, ImageFont
from moviepy import VideoFileClip  # âœ… 2.x æ¨èå†™æ³•
import imagehash
from insightface.app import FaceAnalysis
from datetime import datetime

import sys  # âœ… æ–°å¢


class HeroGridVideo:
    """
    ç”Ÿæˆã€Œä¸»å›¾ 2x2 å·¦ä¸Š + å…¶ä½™æŒ‰è¡Œå¡«å……ã€çš„è§†é¢‘ä¹å®«æ ¼/å¤šå®«æ ¼é¢„è§ˆå›¾ã€‚
    - è‡ªåŠ¨æ ¹æ®è§†é¢‘æ—¶é•¿å†³å®šç½‘æ ¼è§„æ¨¡ä¸é‡‡æ ·æ•°é‡
    - ä¸»å›¾ä»¥ã€Œäººè„¸é¢ç§¯ Ã— æ¸…æ™°åº¦(æ‹‰æ™®æ‹‰æ–¯æ–¹å·®)ã€è¯„åˆ†ï¼Œé™„è¿‘ç²¾ä¿®
    - è¾…åŠ©å›¾ç”¨ dhash åšå¤šæ ·æ€§ç­›é€‰ï¼Œé¿å…ä¸ä¸»å›¾/å½¼æ­¤è¿‡è¿‘
    - è‡ªåŠ¨æ£€æµ‹ç»Ÿä¸€é»‘è¾¹ï¼ˆletterboxï¼‰ï¼Œä¸€è‡´æ—¶ç»Ÿä¸€å»é»‘è¾¹å†æ’ç‰ˆ
    """

    # =========================
    # åˆå§‹åŒ– & åŸºæœ¬è¾“å‡º
    # =========================
    def __init__(
        self,
        font_path: Optional[str] = "fonts/Roboto_Condensed-Regular.ttf",
        providers: Optional[list] = None,
        det_size: Tuple[int, int] = (640, 640),
        verbose: bool = True,
    ):
        """
        :param font_path: æ°´å°å­—ä½“è·¯å¾„
        :param providers: InsightFace æ¨ç†åç«¯ï¼ˆé»˜è®¤ CPUï¼‰
        :param det_size: InsightFace æ£€æµ‹å°ºå¯¸
        :param verbose: æ§åˆ¶å°é˜¶æ®µæç¤ºä¸è¿›åº¦æ¡
        """
        self.font_path = font_path
        self.providers = providers or ["CPUExecutionProvider"]
        self.det_size = det_size
        self.verbose = verbose

        self._stage("åˆå§‹åŒ– InsightFace æ¨¡å‹ä¸­ â€¦")
        self.app = FaceAnalysis(providers=self.providers)
        # ctx_id=0 è¡¨ç¤ºç¬¬ä¸€ä¸ªè®¾å¤‡ï¼ŒONNX Runtime CPU æ—¶æ— å½±å“ï¼›å¦‚ä½¿ç”¨ GPU å¯è‡ªè¡Œè°ƒæ•´
        self.app.prepare(ctx_id=0, det_size=self.det_size)
        self._stage("æ¨¡å‹åˆå§‹åŒ–å®Œæˆã€‚")

    # =========================
    # å¯¹å¤–ä¸»æ–¹æ³•
    # =========================
    def generate(
        self,
        video_path: str,
        preview_basename: str = None,
        sample_count: Optional[int] = None,          # å…è®¸å¤–éƒ¨è¦†ç›–ï¼›ä¸ä¼ åˆ™æŒ‰æ—¶é•¿è‡ªåŠ¨
        num_aux: Optional[int] = None,               # å…è®¸å¤–éƒ¨è¦†ç›–ï¼›ä¸ä¼ åˆ™æŒ‰æ—¶é•¿è‡ªåŠ¨
        manual_times: Optional[List[str | float | int]] = None,
        content_id: Optional[int] = None,            # âœ… æ–°å¢å‚æ•°
    ) -> Dict[str, Any]:
        """
        ç”Ÿæˆç½‘æ ¼å›¾å¹¶è¿”å›å…ƒæ•°æ®ï¼ˆè¾“å‡ºè·¯å¾„ã€ä¸»å›¾æ—¶é—´ã€è¾…åŠ©å¸§æ—¶é—´ç­‰ï¼‰
        """
        ts_prefix = ''

        # âœ… æ”¹ï¼šè¾“å‡ºä½ç½®æ”¹ä¸ºè§†é¢‘æ‰€åœ¨ç›®å½•ä¸‹çš„ preview å­ç›®å½•
        video_path_obj = Path(video_path)
        video_stem = video_path_obj.stem
        video_dir = video_path_obj.parent
        preview_dir = video_dir / "preview"
        preview_dir.mkdir(parents=True, exist_ok=True)

        # âœ… æ‹¼æ¥è¾“å‡ºè·¯å¾„ï¼ˆå¤§æ‹¼å›¾ï¼‰
        out_dir = preview_dir
        out_path = str(out_dir / f"{video_stem}.jpg")

        # âœ… è‹¥ä¼ å…¥ content_idï¼Œåˆ™æµ®æ°´å°ç”¨ content_idï¼Œå¦åˆ™ç”¨è§†é¢‘æ–‡ä»¶å
        watermark_text = str(content_id) if content_id else video_stem

        # ts_prefix = datetime.now().strftime("%Y%m%d%H%M%S_")
        # out_dir = Path(preview_basename).parent
        # base_name = Path(preview_basename).name
        # # out_dir.mkdir(parents=True, exist_ok=True)
        # # out_path = str(out_dir / f"{ts_prefix}{base_name}.jpg")

        # video_stem = Path(video_path).stem           # ğŸ”¹ä»è§†é¢‘åå–ä¸»å¹²å
        # out_dir.mkdir(parents=True, exist_ok=True)
        # out_path = str(out_dir / f"{video_stem}.jpg")  # ğŸ”¹æ”¹æˆä»¥è§†é¢‘åå‘½å

        with VideoFileClip(video_path, audio=False) as clip:
            duration = max(float(clip.duration or 0.01), 0.01)

            # è‡ªåŠ¨å¸ƒå±€ä¸é‡‡æ ·é…ç½®
            auto_cfg = self._decide_layout_by_duration(duration)
            cols = auto_cfg["cols"]
            rows = auto_cfg["rows"]
            auto_num_aux = auto_cfg["num_aux"]
            auto_sample_count = auto_cfg["sample_count"]

            # å…è®¸å¤–éƒ¨è¦†ç›–
            if num_aux is None:
                num_aux = auto_num_aux
            if sample_count is None:
                sample_count = auto_sample_count

            # === ä¸»å›¾ç²—é€‰å€™é€‰å¸§ ===
            hero_times = np.linspace(0, duration - (duration / (sample_count + 1)), sample_count, endpoint=True)
            hero_frames: List[Tuple[float, Image.Image]] = []
            for t in hero_times:
                try:
                    hero_frames.append((float(t), Image.fromarray(clip.get_frame(float(t)))))
                except Exception:
                    pass
            if not hero_frames:
                hero_frames = [(0.0, Image.fromarray(clip.get_frame(0.0)))]

            # é€‰ä¸»å›¾ï¼ˆç²—é€‰ + ç²¾ä¿®ï¼‰
            hero_img, hero_meta = self._choose_hero_frame(hero_frames)
            refined_img, refined_meta = self._refine_hero_nearby(
                clip,
                hero_time=hero_meta.get("time", 0.0),
                window=3,
                step=0.3,
                min_face_area=1e-4,
            )
            if refined_img is not None:
                hero_img = refined_img
                hero_meta.update(refined_meta)

            hero_hash = imagehash.dhash(hero_img)

            # === æ‰‹åŠ¨æ—¶é—´ç‚¹ä¼˜å…ˆ ===
            manual_frames: List[Tuple[float, Image.Image]] = []
            manual_hashes: List[imagehash.ImageHash] = []
            manual_used_times: List[float] = []

            if manual_times:
                duration_eps = max(duration - 1e-3, 0.0)
                parsed = []
                for t in manual_times:
                    try:
                        sec = self._parse_time_to_seconds(t)
                        parsed.append(min(max(0.0, float(sec)), duration_eps))
                    except Exception:
                        continue
                parsed = sorted(set(round(x, 3) for x in parsed))
                for t in parsed:
                    img = self._safe_get_frame(clip, t)
                    if img is None:
                        continue
                    h = imagehash.dhash(img)
                    if abs(h - hero_hash) < 6:
                        continue
                    if manual_hashes and any(abs(h - mh) < 6 for mh in manual_hashes):
                        continue
                    manual_frames.append((float(t), img))
                    manual_hashes.append(h)
                    manual_used_times.append(float(t))
                    if len(manual_frames) >= num_aux:
                        break

            # === è‡ªåŠ¨è¡¥é½è¾…åŠ©å¸§ï¼ˆé¿å¼€ä¸»å›¾ä¸å·²é€‰æ‰‹åŠ¨å¸§ï¼‰ ===
            need_auto = max(0, num_aux - len(manual_frames))
            auto_frames: List[Tuple[float, Image.Image]] = []
            if need_auto > 0:
                auto_frames = self._extract_diverse_frames(
                    clip,
                    num_frames=need_auto,
                    extra=6,
                    exclude_hashes=[hero_hash] + manual_hashes,
                    exclude_thr=6,
                )

            aux_frames = (manual_frames + auto_frames)[:num_aux]

            # === è‹¥é»‘è¾¹ä¸€è‡´ï¼šç»Ÿä¸€è£åˆ‡åˆ°å›ºå®šé•¿å®½æ¯”ï¼ˆå»é»‘è¾¹ï¼‰ï¼Œå†è¿›å…¥æ’ç‰ˆ ===
            judge_imgs = [hero_img] + [img for _, img in aux_frames[:15]]
            lt_rb_frac = self._auto_detect_uniform_letterbox(
                judge_imgs,
                thr=32,
                ratio=0.95,
                max_frac=0.35,
                tolerance_px=8,
                min_consensus=0.6,
            )

            if lt_rb_frac is not None:
                self._stage("æ£€æµ‹åˆ°ä¸€è‡´é»‘è¾¹ï¼Œå°†ç»Ÿä¸€å»é™¤å¹¶ä¿æŒå›ºå®šé•¿å®½æ¯”ã€‚")
                def _apply_frac_crop(img: Image.Image, frac_box: tuple[float, float, float, float]) -> Image.Image:
                    l_frac, t_frac, r_frac, b_frac = frac_box
                    W, H = img.size
                    left   = int(round(W * l_frac))
                    top    = int(round(H * t_frac))
                    right  = int(round(W * r_frac))
                    bottom = int(round(H * b_frac))
                    left   = max(0, min(left, W - 1))
                    top    = max(0, min(top, H - 1))
                    right  = max(left + 1, min(right, W - 1))
                    bottom = max(top + 1, min(bottom, H - 1))
                    return img.crop((left, top, right + 1, bottom + 1))

                hero_img = _apply_frac_crop(hero_img, lt_rb_frac)
                aux_frames = [(t, _apply_frac_crop(img, lt_rb_frac)) for (t, img) in aux_frames]
            else:
                self._stage("æœªæ£€æµ‹åˆ°ä¸€è‡´é»‘è¾¹ï¼ˆå¯èƒ½æ˜¯ç°è¾¹/å…±è¯†ä¸è¶³/åšåº¦å·®å¼‚å¤§ï¼‰ï¼Œä¿æŒåŸå›¾æ¯”ä¾‹ã€‚")


            # ======== é€å¸§å•ç‹¬ä¿å­˜ï¼ˆä¸»å›¾ + è¾…åŠ©å¸§ï¼‰ ========
            video_stem = Path(video_path).stem
            safe_stem = self._sanitize_filename(video_stem)
            single_dir = video_dir / f"stills"
            single_dir.mkdir(parents=True, exist_ok=True)

            # ä¿å­˜ä¸»å›¾
            hero_time_sec = float(hero_meta.get("time", 0.0))
            hero_time_str = self._format_zh_time(hero_time_sec)
            hero_text = f"â–¶ï¸ {hero_time_str}"
            hero_img_wm = self._add_watermark(hero_img.copy(), hero_text)
            hero_out = single_dir / f"{hero_text}.jpg"
            hero_img_wm.save(hero_out, quality=90, optimize=True)

            # ä¿å­˜è¾…åŠ©å¸§
            for t, img in aux_frames:
                ts_str = self._format_zh_time(float(t))
                aux_text = f"{safe_stem}_{ts_str}"
                aux_img_wm = self._add_watermark(img.copy(), aux_text)
                aux_out = single_dir / f"{aux_text}.jpg"
                aux_img_wm.save(aux_out, quality=90, optimize=True)

        # ======== æ’ç‰ˆè¾“å‡º ========
        if aux_frames:
            base_w, base_h = aux_frames[0][1].width, aux_frames[0][1].height
        else:
            base_w, base_h = hero_img.size

        cell_w, cell_h = base_w, base_h
        hero_w, hero_h = cell_w * 2, cell_h * 2

        grid_w, grid_h = cell_w * cols, cell_h * rows
        grid = Image.new("RGB", (grid_w, grid_h), (0, 0, 0))

        # ä¸»å›¾å¡« 2Ã—2 åŒºåŸŸï¼ˆletterboxï¼Œä¸è£åˆ‡ï¼‰
        hero_canvas = self._fit_into_cell(hero_img, hero_w, hero_h, bg=(0, 0, 0))
        grid.paste(hero_canvas, (0, 0))

        # ä½™æ ¼åæ ‡é¡ºåº
        coords = self._grid_coords_with_hero_first(cols, rows)

        # é€æ ¼è´´å›¾ï¼ˆæ¯æ ¼ letterboxï¼‰
        for (gx, gy), (_, img) in zip(coords, aux_frames):
            cell_canvas = self._fit_into_cell(img, cell_w, cell_h, bg=(0, 0, 0))
            grid.paste(cell_canvas, (gx * cell_w, gy * cell_h))

        # æ°´å°æ–‡å­—
        self._stage("æ‹¼æ¥ç½‘æ ¼ä¸æ°´å° â€¦")
        draw = ImageDraw.Draw(grid)
        font = self._load_msyh_font(size=max(14, int(cell_h * 0.20)))
        bbox = draw.textbbox((0, 0), watermark_text, font=font)
        text_w, text_h = bbox[2] - bbox[0], bbox[3] - bbox[1]
        margin = 64
        x = grid.width - text_w - margin
        y = grid.height - text_h - margin
        self._draw_text_with_outline(draw, (x, y), watermark_text, font)

        grid.save(out_path, quality=90, optimize=True)
        self._stage(f"å·²ä¿å­˜ï¼š{out_path}")


        return {
            "output_path": out_path,
            "grid_cols": cols, "grid_rows": rows,
            "hero_time": round(hero_meta.get("time", 0.0), 3),
            "hero_score": round(hero_meta.get("score", 0.0), 6),
            "aux_times": [round(t, 3) for t, _ in aux_frames],
            "manual_used_times": [round(t, 3) for t in manual_used_times] if manual_times else [],
            "sample_count_used": sample_count,
        }

    # =========================
    # å†…éƒ¨ï¼šå¸ƒå±€ä¸æŠ½å¸§
    # =========================
    @staticmethod
    def _decide_layout_by_duration(duration_sec: float) -> dict:
        """
        - <  5 min: 3x4,  ä¸»å›¾4 + è¾…åŠ©8  = 12æ ¼, sample_count=100
        - 5-10 min: 4x4,  ä¸»å›¾4 + è¾…åŠ©12 = 16æ ¼, sample_count=150
        - 10-30 min:5x5,  ä¸»å›¾4 + è¾…åŠ©21 = 25æ ¼, sample_count=200
        - > 30 min: 6x6,  ä¸»å›¾4 + è¾…åŠ©32 = 36æ ¼, sample_count=300
        """
        m = duration_sec / 60.0
        if m < 5:
            return {"cols": 3, "rows": 4, "num_aux": 8,  "sample_count": 100}
        elif m < 10:
            return {"cols": 4, "rows": 4, "num_aux": 12, "sample_count": 150}
        elif m < 30:
            return {"cols": 5, "rows": 5, "num_aux": 21, "sample_count": 200}
        else:
            return {"cols": 6, "rows": 6, "num_aux": 32, "sample_count": 300}

    @staticmethod
    def _grid_coords_with_hero_first(cols: int, rows: int) -> List[Tuple[int, int]]:
        coords = []
        for y in range(rows):
            for x in range(cols):
                if x < 2 and y < 2:  # è·³è¿‡ä¸»å›¾ 2x2 å ä½
                    continue
                coords.append((x, y))
        return coords

    # =========================
    # å†…éƒ¨ï¼šå·¥å…·å‡½æ•°
    # =========================
    @staticmethod
    def _fit_into_cell(img: Image.Image, cell_w: int, cell_h: int, bg=(0, 0, 0)) -> Image.Image:
        iw, ih = img.size
        if iw == 0 or ih == 0:
            return Image.new("RGB", (cell_w, cell_h), bg)

        scale = min(cell_w / iw, cell_h / ih)
        new_w = max(1, int(round(iw * scale)))
        new_h = max(1, int(round(ih * scale)))
        resized = img.resize((new_w, new_h), Image.LANCZOS)

        canvas = Image.new("RGB", (cell_w, cell_h), bg)
        ox = (cell_w - new_w) // 2
        oy = (cell_h - new_h) // 2
        canvas.paste(resized, (ox, oy))
        return canvas

    @staticmethod
    def _parse_time_to_seconds(t) -> float:
        """
        æ”¯æŒ: float/intï¼ˆç§’ï¼‰ã€"mm:ss"ã€"hh:mm:ss"ã€"ss"ï¼ˆå¯å«å°æ•°ï¼‰
        """
        if isinstance(t, (int, float)):
            return float(t)
        s = str(t).strip()
        parts = s.split(":")
        try:
            if len(parts) == 1:
                return float(parts[0])
            elif len(parts) == 2:
                m = float(parts[0]); sec = float(parts[1])
                return m * 60 + sec
            elif len(parts) == 3:
                h = float(parts[0]); m = float(parts[1]); sec = float(parts[2])
                return h * 3600 + m * 60 + sec
        except ValueError:
            pass
        raise ValueError(f"æ— æ³•è§£ææ—¶é—´æ ¼å¼: {t!r}")

    @staticmethod
    def _safe_get_frame(clip: VideoFileClip, t: float) -> Optional[Image.Image]:
        try:
            return Image.fromarray(clip.get_frame(float(t)))
        except Exception:
            return None

    @staticmethod
    def _lap_var(pil_img: Image.Image) -> float:
        arr = np.array(pil_img.convert("L"), dtype=np.float32)
        k = np.array([[0, 1, 0],
                      [1,-4, 1],
                      [0, 1, 0]], dtype=np.float32)
        h, w = arr.shape
        pad = 1
        padded = np.pad(arr, pad, mode="edge")
        out = np.zeros_like(arr)
        for y in range(h):
            for x in range(w):
                region = padded[y:y+3, x:x+3]
                out[y, x] = (region * k).sum()
        return float(out.var())

    def _choose_hero_frame(self, frames: List[Tuple[float, Image.Image]]):
        self._stage(f"å¼€å§‹ç²—é€‰ä¸»å›¾ï¼šå…± {len(frames)} å¸§åšäººè„¸æ£€æµ‹")
        start_ts = time.time()
        best = None
        for idx, (t, img) in enumerate(frames, start=1):
            arr = np.array(img)
            faces = self.app.get(arr)
            if not faces:
                score = 0.0
            else:
                h, w = arr.shape[:2]
                areas = []
                for f in faces:
                    x1, y1, x2, y2 = map(int, f.bbox)
                    x1, y1, x2, y2 = max(0,x1), max(0,y1), min(w,x2), min(h,y2)
                    area = max(0, x2-x1) * max(0, y2-y1)
                    areas.append(area / (w*h))
                score = float(np.sum(areas))
            candidate = (score, len(faces), -t, img, {"time": float(t), "score": score})
            if best is None or candidate > best:
                best = candidate

            self._progress("ç²—é€‰è¿›åº¦", idx, len(frames), start_ts, every=5)

        self._stage(f"ç²—é€‰å®Œæˆï¼šä¸»å›¾æ—¶é—´ {best[4]['time']:.3f}sï¼Œå¾—åˆ† {best[4]['score']:.6f}")
        return best[3], best[4]

    def _refine_hero_nearby(
        self,
        clip: VideoFileClip,
        hero_time: float,
        window: float = 1.0,
        step: float = 0.1,
        min_face_area: float = 1e-4,
    ) -> Tuple[Optional[Image.Image], Optional[dict]]:
        """
        åœ¨ä¸»å›¾é™„è¿‘äºŒæ¬¡æœç´¢æ›´ä¼˜ä¸»å›¾ï¼š
        è¯„åˆ† = äººè„¸æ€»é¢ç§¯(å½’ä¸€åŒ–) * æ¸…æ™°åº¦(æ‹‰æ™®æ‹‰æ–¯æ–¹å·®)
        """
        duration = max(clip.duration, 0.01)
        t0 = max(0.0, hero_time - window)
        t1 = min(duration - 1e-3, hero_time + window)

        times = np.arange(t0, t1 + 1e-9, step, dtype=np.float64)
        total = len(times)
        if total <= 0:
            self._stage("ç²¾ä¿®åŒºé—´ä¸ºç©ºï¼Œè·³è¿‡ã€‚")
            return None, None

        self._stage(f"å¼€å§‹ç²¾ä¿®ä¸»å›¾ï¼šçª—å£ {t0:.2f}s~{t1:.2f}sï¼Œæ­¥é•¿ {step}sï¼Œå…± {total} å¸§")
        start_ts = time.time()
        last_tick = start_ts

        best = None
        cnt_scanned = 0
        cnt_has_face = 0
        cnt_filtered_small = 0
        last_best_score = -1.0

        frame0 = Image.fromarray(clip.get_frame(float(times[0])))
        _ = np.array(frame0).shape[:2]  # é¢„çƒ­

        for i, t in enumerate(times, start=1):
            self._progress("ç²¾ä¿®è¿›åº¦", i, total, start_ts, every=10)
            cnt_scanned += 1

            try:
                img = Image.fromarray(clip.get_frame(float(t)))
            except Exception:
                now = time.time()
                if now - last_tick >= 1.0:
                    self._stage(f"æ‰«æä¸­â€¦ {i}/{total} | æœ‰è„¸ {cnt_has_face} | è¿‡æ»¤(å°è„¸) {cnt_filtered_small} | å½“å‰æœ€ä½³ {max(0.0,last_best_score):.2f}")
                    last_tick = now
                continue

            arr = np.array(img)
            faces = self.app.get(arr)
            if not faces:
                now = time.time()
                if now - last_tick >= 1.0:
                    self._stage(f"æ‰«æä¸­â€¦ {i}/{total} | æœ‰è„¸ {cnt_has_face} | è¿‡æ»¤(å°è„¸) {cnt_filtered_small} | å½“å‰æœ€ä½³ {max(0.0,last_best_score):.2f}")
                    last_tick = now
                continue

            H, W = arr.shape[:2]
            area_sum = 0.0
            for f in faces:
                x1, y1, x2, y2 = map(int, f.bbox)
                x1, y1, x2, y2 = max(0,x1), max(0,y1), min(W,x2), min(H,y2)
                a = max(0, x2-x1) * max(0, y2-y1) / (W*H)
                if a >= min_face_area:
                    area_sum += a

            if area_sum > 0:
                cnt_has_face += 1
                sharp = self._lap_var(img)
                score = area_sum * sharp
                candidate = (score, -abs(t-hero_time), img, {"time": float(t), "score_face_area": area_sum, "sharp": sharp, "score": float(score)})

                if best is None or candidate > best:
                    best = candidate
                    last_best_score = best[0]
                    meta = best[3]
                    self._stage(f"â†‘ æ–°æœ€ä½³ï¼št={meta['time']:.3f}s  é¢ç§¯={meta['score_face_area']:.5f}  æ¸…æ™°={meta['sharp']:.2f}  åˆ†æ•°={meta['score']:.2f}")
            else:
                cnt_filtered_small += 1

            now = time.time()
            if now - last_tick >= 1.0:
                self._stage(f"æ‰«æä¸­â€¦ {i}/{total} | æœ‰è„¸ {cnt_has_face} | è¿‡æ»¤(å°è„¸) {cnt_filtered_small} | å½“å‰æœ€ä½³ {max(0.0,last_best_score):.2f}")
                last_tick = now

        if best is None:
            self._stage("ç²¾ä¿®æœªæ‰¾åˆ°æ›´ä¼˜å¸§ï¼Œæ²¿ç”¨ç²—é€‰ä¸»å›¾")
            return None, None

        meta = best[3]
        self._stage(f"ç²¾ä¿®å®Œæˆï¼šæ–°ä¸»å›¾æ—¶é—´ {meta['time']:.3f}sï¼Œç»¼åˆåˆ† {meta['score']:.2f} | æ€»æ‰« {cnt_scanned}ï¼Œæœ‰è„¸ {cnt_has_face}ï¼Œå°è„¸è¿‡æ»¤ {cnt_filtered_small}")
        return best[2], meta

    def _extract_diverse_frames2(
        self,
        clip: VideoFileClip,
        num_frames: int,
        extra: int = 6,
        exclude_hashes: Optional[List[imagehash.ImageHash]] = None,
        exclude_thr: int = 6,
    ) -> List[Tuple[float, Image.Image]]:
        """
        ä»è§†é¢‘ä¸­å‡åŒ€æŠ½æ ·ï¼ˆnum_frames + extraï¼‰ï¼Œç”¨æ„ŸçŸ¥å“ˆå¸Œè´ªå¿ƒé€‰å–å¤šæ ·å¸§ã€‚
        - exclude_hashes / exclude_thrï¼šç”¨äºæ’é™¤ä¸ä¸»å›¾ï¼ˆæˆ–å…¶å®ƒï¼‰è¿‡ç›¸è¿‘çš„å¸§ã€‚
        - è‡ªé€‚åº”é˜ˆå€¼ï¼šæ ¹æ®å€™é€‰å¸§é—´å“ˆå¸Œè·ç¦»çš„åˆ†ä½æ•°è°ƒèŠ‚å¤šæ ·æ€§ç­›é€‰å¼ºåº¦ã€‚
        """
        self._stage(f"å¼€å§‹æŠ½è¾…åŠ©å¸§ï¼šå€™é€‰ {num_frames + extra}ï¼Œç›®æ ‡ {num_frames}")

        duration = max(float(clip.duration or 0.01), 0.01)
        times = np.linspace(0.0, duration, num_frames + extra, endpoint=False, dtype=np.float64)

        raw_frames: List[Tuple[float, Image.Image]] = []
        start_ts = time.time()

        for k, t in enumerate(times, start=1):
            try:
                img = Image.fromarray(clip.get_frame(float(t)))
                raw_frames.append((float(t), img))
            except Exception:
                pass
            self._progress("å¤šæ ·æ€§ç­›é€‰", k, len(times), start_ts, every=10)

        if not raw_frames:
            try:
                return [(0.0, Image.fromarray(clip.get_frame(0.0)))]
            except Exception:
                return []

        hashes: List[imagehash.ImageHash] = [imagehash.dhash(img) for _, img in raw_frames]

        dists = []
        for i in range(len(hashes)):
            hi = hashes[i]
            for j in range(i + 1, len(hashes)):
                dists.append(abs(hi - hashes[j]))
        adaptive_thr = max(5, int(np.percentile(dists, 25))) if dists else 6

        selected: List[Tuple[float, Image.Image]] = []
        selected_hashes: List[imagehash.ImageHash] = []

        for (t, img), h in zip(raw_frames, hashes):
            if exclude_hashes and any(abs(h - eh) < exclude_thr for eh in exclude_hashes):
                continue
            if selected_hashes and any(abs(h - sh) < adaptive_thr for sh in selected_hashes):
                continue

            selected.append((t, img))
            selected_hashes.append(h)
            if len(selected) >= num_frames:
                break

        if len(selected) < num_frames:
            for idx, ((t, img), h) in enumerate(zip(raw_frames, hashes)):
                if len(selected) >= num_frames:
                    break
                if (t, img) in selected:
                    continue
                if exclude_hashes and any(abs(h - eh) < exclude_thr for eh in exclude_hashes):
                    continue
                if not selected_hashes or all(abs(h - sh) >= max(4, adaptive_thr - 2) for sh in selected_hashes):
                    selected.append((t, img))
                    selected_hashes.append(h)

        if len(selected) < num_frames:
            for (t, img), h in zip(raw_frames, hashes):
                if len(selected) >= num_frames:
                    break
                if (t, img) in selected:
                    continue
                if exclude_hashes and any(abs(h - eh) < exclude_thr for eh in exclude_hashes):
                    continue
                selected.append((t, img))

        selected.sort(key=lambda x: x[0])
        selected = selected[:num_frames]

        self._stage(f"è¾…åŠ©å¸§å®Œæˆï¼šå®é™…é€‰å– {len(selected)} å¼ ")
        return selected


    def _extract_diverse_frames(
        self,
        clip: VideoFileClip,
        num_frames: int,
        extra: int = 6,
        exclude_hashes: Optional[List[imagehash.ImageHash]] = None,
        exclude_thr: int = 6,
    ) -> List[Tuple[float, Image.Image]]:
        """
        ä»è§†é¢‘ä¸­å‡åŒ€æŠ½æ ·ï¼ˆnum_frames + extraï¼‰ï¼Œç”¨æ„ŸçŸ¥å“ˆå¸Œè´ªå¿ƒé€‰å–å¤šæ ·å¸§ã€‚
        å¿…è¾¾ç›®æ ‡æ•°ï¼šä¸è¶³æ—¶é€æ­¥æ”¾å®½ï¼Œæœ€åç”¨å‡åŒ€é‡‡æ ·å›å¡«ï¼Œç¡®ä¿è¿”å›é•¿åº¦ == num_framesã€‚
        """
        self._stage(f"å¼€å§‹æŠ½è¾…åŠ©å¸§ï¼šç›®æ ‡ {num_frames}ï¼Œå€™é€‰ {num_frames + extra}")

        duration = max(float(clip.duration or 0.01), 0.01)
        # ç¬¬ä¸€è½®å€™é€‰æ—¶é—´ï¼ˆå‡åŒ€å–æ ·ï¼Œä¸å«æœ«å°¾ç«¯ç‚¹ï¼Œå‡å°‘é»‘å¸§/è½¬åœºå¹²æ‰°ï¼‰
        times = np.linspace(0.0, duration, num_frames + extra, endpoint=False, dtype=np.float64)

        raw_frames: List[Tuple[float, Image.Image]] = []
        start_ts = time.time()
        for k, t in enumerate(times, start=1):
            try:
                img = Image.fromarray(clip.get_frame(float(t)))
                raw_frames.append((float(t), img))
            except Exception:
                pass
            self._progress("å¤šæ ·æ€§ç­›é€‰", k, len(times), start_ts, every=10)

        # è‹¥å®Œå…¨æŠ“ä¸åˆ°å¸§ï¼Œå°è¯• 0 ç§’å…œåº•
        if not raw_frames:
            try:
                return [(0.0, Image.fromarray(clip.get_frame(0.0)))] * max(1, num_frames)
            except Exception:
                return []

        # é¢„è®¡ç®—å“ˆå¸Œ
        hashes: List[imagehash.ImageHash] = [imagehash.dhash(img) for _, img in raw_frames]

        # è®¡ç®—å€™é€‰å¸§ä¹‹é—´çš„è·ç¦»ç”¨äºè‡ªé€‚åº”é˜ˆå€¼
        dists = []
        for i in range(len(hashes)):
            hi = hashes[i]
            for j in range(i + 1, len(hashes)):
                dists.append(abs(hi - hashes[j]))
        adaptive_thr = max(5, int(np.percentile(dists, 25))) if dists else 6

        # -----------------------
        # Pass 1ï¼šä¸¥æ ¼å¤šæ ·æ€§é€‰å–
        # -----------------------
        def greedy_select(thr: int) -> List[Tuple[float, Image.Image]]:
            selected: List[Tuple[float, Image.Image]] = []
            selected_hashes: List[imagehash.ImageHash] = []
            for (t, img), h in zip(raw_frames, hashes):
                # æ’é™¤ä¸æŒ‡å®šå“ˆå¸Œè¿‡è¿‘çš„å¸§ï¼ˆé€šå¸¸æ˜¯ä¸»å›¾ç­‰ï¼‰
                if exclude_hashes and any(abs(h - eh) < exclude_thr for eh in exclude_hashes):
                    continue
                # ä¸å·²é€‰è¿‡è¿‘åˆ™è·³è¿‡
                if selected_hashes and any(abs(h - sh) < thr for sh in selected_hashes):
                    continue
                selected.append((t, img))
                selected_hashes.append(h)
                if len(selected) >= num_frames:
                    break
            return selected

        selected = greedy_select(adaptive_thr)
        if len(selected) < num_frames:
            # -----------------------
            # Pass 2ï¼šæ”¾å®½å¤šæ ·æ€§é˜ˆå€¼
            # -----------------------
            loose_thr = max(3, adaptive_thr - 2)
            selected = greedy_select(loose_thr)

        if len(selected) < num_frames:
            # -----------------------
            # Pass 3ï¼šæ— å·®åˆ«è¡¥é½ï¼ˆä»…é¿å¼€ exclude_hashesï¼‰
            # -----------------------
            picked = set(id(img) for _, img in selected)
            for (t, img), h in zip(raw_frames, hashes):
                if len(selected) >= num_frames:
                    break
                if id(img) in picked:
                    continue
                if exclude_hashes and any(abs(h - eh) < exclude_thr for eh in exclude_hashes):
                    continue
                selected.append((t, img))
                picked.add(id(img))

        if len(selected) < num_frames:
            # -----------------------
            # Pass 4ï¼šå‡åŒ€é‡‡æ ·å›å¡«ï¼ˆé¿å…å·²é€‰æ—¶é—´ç‚¹ï¼‰
            # -----------------------
            want = num_frames - len(selected)
            # ç”ŸæˆäºŒè½®å‡åŒ€æ—¶é—´ï¼ˆé”™ä½ä¸€ç‚¹ç‚¹ï¼Œé¿å¼€ä¸ç¬¬ä¸€è½®å®Œå…¨é‡å¤ï¼‰
            times2 = np.linspace(0.0 + duration/(2*(num_frames+extra)), duration, want * 2, endpoint=False, dtype=np.float64)
            already_times = {round(t, 3) for t, _ in selected}
            filled = 0
            for t in times2:
                if filled >= want:
                    break
                t_ = float(np.clip(t, 0.0, max(duration - 1e-3, 0.0)))
                if round(t_, 3) in already_times:
                    continue
                img = self._safe_get_frame(clip, t_)
                if img is None:
                    continue
                h = imagehash.dhash(img)
                if exclude_hashes and any(abs(h - eh) < exclude_thr for eh in exclude_hashes):
                    continue
                selected.append((t_, img))
                already_times.add(round(t_, 3))
                filled += 1

        if len(selected) < num_frames:
            # -----------------------
            # Pass 5ï¼šæç«¯å…œåº•ï¼ˆå…è®¸é‡å¤æœ€åä¸€å¸§å¡«æ»¡ï¼‰
            # -----------------------
            if selected:
                last_t, last_img = selected[-1]
                while len(selected) < num_frames:
                    selected.append((last_t, last_img))
            else:
                # ç†è®ºä¸Šä¸ä¼šåˆ°è¿™é‡Œ
                try:
                    img0 = Image.fromarray(clip.get_frame(0.0))
                    selected = [(0.0, img0)] * num_frames
                except Exception:
                    selected = []

        # è§„èŒƒåŒ–è¾“å‡ºï¼ˆæŒ‰æ—¶é—´æ’åºï¼Œæˆªæ–­åˆ°ç›®æ ‡æ•°ï¼‰
        selected.sort(key=lambda x: x[0])
        selected = selected[:num_frames]

        self._stage(f"è¾…åŠ©å¸§å®Œæˆï¼šå®é™…é€‰å– {len(selected)} / ç›®æ ‡ {num_frames}")
        return selected


    # =========================
    # å†…éƒ¨ï¼šé»‘è¾¹æ£€æµ‹
    # =========================
    @staticmethod
    def _is_near_black_line(arr_row_or_col: np.ndarray, thr: int = 16, ratio: float = 0.98) -> bool:
        if arr_row_or_col.ndim == 1:
            arr = arr_row_or_col
        else:
            arr = arr_row_or_col
        if arr.ndim == 2 and arr.shape[1] == 3:
            v = arr.max(axis=1)
        else:
            v = arr
        return (v < thr).mean() >= ratio

    def _detect_letterbox_bbox(self, img: Image.Image,
                               thr: int = 16,
                               ratio: float = 0.98,
                               max_frac: float = 0.20) -> Optional[tuple[int, int, int, int]]:
        arr = np.array(img.convert("RGB"))
        H, W = arr.shape[:2]

        top = 0
        while top < H and self._is_near_black_line(arr[top, :, :], thr=thr, ratio=ratio):
            top += 1
        bottom = H - 1
        while bottom > top and self._is_near_black_line(arr[bottom, :, :], thr=thr, ratio=ratio):
            bottom -= 1
        left = 0
        while left < W and self._is_near_black_line(arr[:, left, :], thr=thr, ratio=ratio):
            left += 1
        right = W - 1
        while right > left and self._is_near_black_line(arr[:, right, :], thr=thr, ratio=ratio):
            right -= 1

        crop_w = right - left + 1
        crop_h = bottom - top + 1
        if crop_w <= 0 or crop_h <= 0:
            return None

        if (top / H > max_frac) or ((H - 1 - bottom) / H > max_frac) or \
           (left / W > max_frac) or ((W - 1 - right) / W > max_frac):
            return None

        if top == 0 and left == 0 and bottom == H - 1 and right == W - 1:
            return None

        return (left, top, right, bottom)

    def _auto_detect_uniform_letterbox(self,
                                       frames: List[Image.Image],
                                       thr: int = 16,
                                       ratio: float = 0.98,
                                       max_frac: float = 0.20,
                                       tolerance_px: int = 4,
                                       min_consensus: float = 0.8) -> Optional[tuple[float, float, float, float]]:
        if not frames:
            return None

        sample = frames[:min(20, len(frames))]
        W0, H0 = sample[0].size
        boxes = []
        for img in sample:
            if img.size != (W0, H0):
                tmp = img.resize((W0, H0), Image.LANCZOS)
                box = self._detect_letterbox_bbox(tmp, thr=thr, ratio=ratio, max_frac=max_frac)
            else:
                box = self._detect_letterbox_bbox(img, thr=thr, ratio=ratio, max_frac=max_frac)
            if box:
                boxes.append(box)

        if not boxes:
            return None

        def group_with_ref(ref_box):
            l0, t0, r0, b0 = ref_box
            group = [ref_box]
            for bx in boxes:
                if bx is ref_box:
                    continue
                l, t, r, b = bx
                if abs(l - l0) <= tolerance_px and abs(t - t0) <= tolerance_px and \
                   abs(r - r0) <= tolerance_px and abs(b - b0) <= tolerance_px:
                    group.append(bx)
            return group

        best_group = []
        for ref in boxes:
            g = group_with_ref(ref)
            if len(g) > len(best_group):
                best_group = g

        if len(best_group) / len(sample) < min_consensus:
            return None

        ls, ts, rs, bs = zip(*best_group)
        l_med, t_med, r_med, b_med = int(np.median(ls)), int(np.median(ts)), int(np.median(rs)), int(np.median(bs))
        l_frac = l_med / W0
        t_frac = t_med / H0
        r_frac = r_med / W0
        b_frac = b_med / H0
        print(f"[letterbox] use frac box = {l_frac:.4f},{t_frac:.4f},{r_frac:.4f},{b_frac:.4f}", flush=True)
        return (l_frac, t_frac, r_frac, b_frac)

    # =========================
    # å†…éƒ¨ï¼šç»˜åˆ¶ä¸å­—ä½“
    # =========================
    @staticmethod
    def _safe_load_font(font_path: Optional[str], size: int):
        if font_path and os.path.exists(font_path):
            try:
                return ImageFont.truetype(font_path, size=size)
            except Exception:
                pass
        try:
            return ImageFont.truetype("DejaVuSans.ttf", size=size)
        except Exception:
            return ImageFont.load_default()

    @staticmethod
    def _draw_text_with_outline(draw, xy, text, font, fill=(255, 255, 255, 220)):
        x, y = xy
        for dx, dy in [(-1,0),(1,0),(0,-1),(0,1),(-1,-1),(1,-1),(-1,1),(1,1)]:
            draw.text((x+dx, y+dy), text, font=font, fill=(0, 0, 0, 200))
        draw.text((x, y), text, font=font, fill=fill)

    
    def _add_watermark(self, img: Image.Image, text: str) -> Image.Image:
        """
        åœ¨å›¾åƒåº•éƒ¨ä¸­å¤®æ·»åŠ æµ®æ°´å°æ–‡å­—ã€‚
        è‡ªåŠ¨æ ¹æ®å›¾ç‰‡å®½åº¦è°ƒæ•´å­—ä½“å¤§å°ï¼Œç¡®ä¿æ–‡å­—å®Œæ•´å‘ˆç°ä¸”ä¸è¿‡å°ã€‚
        """
        draw = ImageDraw.Draw(img)

        # åˆå§‹å­—å·ï¼ˆéšå›¾åƒé«˜åº¦å®šä¸€ä¸ªä¸Šé™ï¼‰
        base_size = max(14, int(img.height * 0.08))
        font = self._load_msyh_font(size=base_size)

        # è®¡ç®—ç›®æ ‡æœ€å¤§å®½åº¦ï¼ˆå›¾å®½çš„ 90%ï¼‰
        max_text_width = int(img.width * 0.9)
        bbox = draw.textbbox((0, 0), text, font=font)
        text_w = bbox[2] - bbox[0]

        # è‹¥å¤ªå®½åˆ™é€æ­¥å‡å°å­—å·ç›´åˆ°åˆé€‚
        while text_w > max_text_width and base_size > 10:
            base_size -= 2
            font = self._load_msyh_font(size=base_size)
            bbox = draw.textbbox((0, 0), text, font=font)
            text_w = bbox[2] - bbox[0]

        # è‹¥å¤ªçª„å¯ç•¥å¾®æ”¾å¤§ä¸€ç‚¹ï¼Œæå‡å¯è¯»æ€§
        while text_w < max_text_width * 0.6 and base_size < int(img.height * 0.12):
            base_size += 2
            font = self._load_msyh_font(size=base_size)
            bbox = draw.textbbox((0, 0), text, font=font)
            text_w = bbox[2] - bbox[0]

        text_h = bbox[3] - bbox[1]
        x = (img.width - text_w) // 2
        y = img.height - text_h - int(img.height * 0.04)

        self._draw_text_with_outline(draw, (x, y), text, font)
        return img



    # =========================
    # æ§åˆ¶å°è¾“å‡º
    # =========================
    def _stage(self, msg: str):
        if self.verbose:
            print(f"[{time.strftime('%H:%M:%S')}] {msg}", flush=True)

    def _progress(self, prefix: str, i: int, total: int, start_ts: float, every: int = 10):
        if not self.verbose:
            return
        if i % every != 0 and i != total:
            return
        elapsed = time.time() - start_ts
        pct = 100.0 * i / total if total else 100.0
        eta = self._fmt_eta(elapsed, i, total)
        print(f"\r{prefix}: {i}/{total} ({pct:5.1f}%)  ETA {eta}", end="", flush=True)

    @staticmethod
    def _fmt_eta(elapsed, done, total):
        if done == 0:
            return "--:--"
        rate = elapsed / done
        remain = rate * (total - done)
        m, s = divmod(int(remain), 60)
        return f"{m:02d}:{s:02d}"

    @staticmethod
    def _format_zh_time(seconds: float) -> str:
        """æŠŠç§’æ•°æ ¼å¼åŒ–ä¸ºä¸­æ–‡ï¼šmmåˆ†ssç§’ æˆ– hhæ—¶mmåˆ†ssç§’ã€‚"""
        total = int(round(max(0, seconds)))
        h, rem = divmod(total, 3600)
        m, s = divmod(rem, 60)
        if h > 0:
            return f"{h:02d}:{m:02d}:{s:02d}"
        return f"{m:02d}:{s:02d}"

    @staticmethod
    def _sanitize_filename(name: str) -> str:
        """ç®€å•æ¸…ç†ä¸ºå¯ç”¨æ–‡ä»¶åï¼ˆè·¨å¹³å°å®‰å…¨ä¸€ç‚¹ï¼‰ã€‚"""
        keep = "-_.()ï¼ˆï¼‰Â·ï¼‹+&@"
        return "".join(ch if ch.isalnum() or ch in keep else "_" for ch in name)


    

    @staticmethod
    def _load_msyh_font(size: int) -> ImageFont.FreeTypeFont:
        """
        å¼ºåˆ¶ä½¿ç”¨å¾®è½¯é›…é»‘ï¼ˆmsyh.ttcï¼‰ï¼Œé¿å…ä¸­æ–‡ä¹±ç ã€‚
        è‹¥è·¯å¾„ä¸å­˜åœ¨åˆ™é€€å›é»˜è®¤å­—ä½“ã€‚
        """
        import sys
        cand = [
            "fonts/msyh.ttc",
            "fonts/msyh.ttf",
        ]
        # Windows ç³»ç»Ÿå­—ä½“è·¯å¾„å…œåº•
        if os.name == "nt":
            win_fonts = os.path.join(os.environ.get("WINDIR", r"C:\Windows"), "Fonts")
            cand += [
                os.path.join(win_fonts, "msyh.ttc"),
                os.path.join(win_fonts, "msyh.ttf"),
            ]
        # macOS/Linux è‹¥ä½ æœ‰ fonts ç›®å½•
        cand += [
            "/usr/share/fonts/truetype/microsoft/msyh.ttc",
            "/usr/share/fonts/truetype/msyh.ttc",
            "/Library/Fonts/msyh.ttc",
        ]

        for fp in cand:
            if os.path.exists(fp):
                try:
                    return ImageFont.truetype(fp, size=size)
                except Exception:
                    continue
        # å…œåº•
        return ImageFont.load_default()



# =========================
# ç¤ºä¾‹ç”¨æ³•ï¼ˆå¯ç›´æ¥è¿è¡Œè°ƒè¯•ï¼‰
# =========================
if __name__ == "__main__":
    import traceback

    try:
        hg = HeroGridVideo(
            font_path="fonts/Roboto_Condensed-Regular.ttf",
            providers=["CPUExecutionProvider"],  # å¦‚éœ€ GPU å¯æŒ‰ç¯å¢ƒæ”¹ä¸º ["CUDAExecutionProvider", "CPUExecutionProvider"]
            det_size=(640, 640),
            verbose=True,
        )
        meta = hg.generate(
            video_path="video/s6614244fe4b06d7f37acee3b.mp4",
            preview_basename="previews/370854",
            # manual_times=["01:34", "04:08", "04:37", "05:11", "08:33"],
            # sample_count=180,
            # num_aux=12,
        )
        print("âœ… ç½‘æ ¼å·²ç”Ÿæˆï¼š", meta["output_path"])
        print("   ä¸»è§’å¸§æ—¶é—´(s)ï¼š", meta["hero_time"], " è¯„åˆ†ï¼š", meta["hero_score"])
        print("   è¾…åŠ©å¸§æ—¶é—´(s)ï¼š", meta["aux_times"])
    except Exception as e:
        print(f"âŒ é”™è¯¯ï¼š{e}")
        traceback.print_exc()
